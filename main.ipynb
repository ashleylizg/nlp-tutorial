{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Divide and prepare Amazon product reviews for food items for Natural Language Toolkit (NLTK) to train a classifier for sentiment analysis to determine positive and negative reviews.\n",
    "\n",
    "**Data Source**: Grocery and Gourmet Food section of [Amazon Review Data (2018)](https://nijianmo.github.io/amazon/index.html) from Jianmo Ni, UCSD\n",
    "\n",
    "**Overview**:\n",
    "- Divide and label the data based on type (positive vs negative)\n",
    "- Prepare the data for analysis through tokenization and removing stop words and punctuation\n",
    "- Find frequency distribution of words\n",
    "- Train and test a classifer to determine positive versus negative reviews\n",
    "- Evaluate the classifier and check most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the main dataset for splitting. This is in a JSON format, but we will load it into a dataframe with pandas for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/Grocery_and_Gourmet_Food_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>11 19, 2014</td>\n",
       "      <td>A1QVBUH9E1V6I8</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>Jamshed Mathur</td>\n",
       "      <td>No adverse comment.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1416355200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 13, 2016</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>itsjustme</td>\n",
       "      <td>Gift for college student.</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>1476316800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>11 21, 2015</td>\n",
       "      <td>A32RD6L701BIGP</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>Krystal Clifton</td>\n",
       "      <td>If you like strong tea, this is for you. It mi...</td>\n",
       "      <td>Strong</td>\n",
       "      <td>1448064000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 12, 2015</td>\n",
       "      <td>A2UY1O1FBGKIE6</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>U. Kane</td>\n",
       "      <td>Love the tea. The flavor is way better than th...</td>\n",
       "      <td>Great tea</td>\n",
       "      <td>1439337600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>05 28, 2015</td>\n",
       "      <td>A3QHVBQYDV7Z6U</td>\n",
       "      <td>4639725183</td>\n",
       "      <td>The Nana</td>\n",
       "      <td>I have searched everywhere until I browsed Ama...</td>\n",
       "      <td>This is the tea I remembered!</td>\n",
       "      <td>1432771200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True  11 19, 2014  A1QVBUH9E1V6I8  4639725183   \n",
       "1        5      True  10 13, 2016  A3GEOILWLK86XM  4639725183   \n",
       "2        5      True  11 21, 2015  A32RD6L701BIGP  4639725183   \n",
       "3        5      True  08 12, 2015  A2UY1O1FBGKIE6  4639725183   \n",
       "4        5      True  05 28, 2015  A3QHVBQYDV7Z6U  4639725183   \n",
       "\n",
       "      reviewerName                                         reviewText  \\\n",
       "0   Jamshed Mathur                                No adverse comment.   \n",
       "1        itsjustme                          Gift for college student.   \n",
       "2  Krystal Clifton  If you like strong tea, this is for you. It mi...   \n",
       "3          U. Kane  Love the tea. The flavor is way better than th...   \n",
       "4         The Nana  I have searched everywhere until I browsed Ama...   \n",
       "\n",
       "                         summary  unixReviewTime vote style image  \n",
       "0                     Five Stars      1416355200  NaN   NaN   NaN  \n",
       "1                 Great product.      1476316800  NaN   NaN   NaN  \n",
       "2                         Strong      1448064000  NaN   NaN   NaN  \n",
       "3                      Great tea      1439337600  NaN   NaN   NaN  \n",
       "4  This is the tea I remembered!      1432771200  NaN   NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main information we will use is the 'overall' score column and the 'reviewText' column. We will create a new dataframe with those first before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_df = df[['overall','reviewText']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>No adverse comment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gift for college student.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>If you like strong tea, this is for you. It mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love the tea. The flavor is way better than th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I have searched everywhere until I browsed Ama...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText\n",
       "0        5                                No adverse comment.\n",
       "1        5                          Gift for college student.\n",
       "2        5  If you like strong tea, this is for you. It mi...\n",
       "3        5  Love the tea. The flavor is way better than th...\n",
       "4        5  I have searched everywhere until I browsed Ama..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_df['overall'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall score category has five rating options. We will be assigning scores 1 and 2 as negative reviews and 4 and 5 as positive, with the reviews with a count of 3 as somewhere in between. We will omit the scores of 3 for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = condensed_df.loc[condensed_df['overall'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews = condensed_df.loc[condensed_df['overall'] < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label both the types of reactions before combining the datasets into one. This will be used for gathering an evenly split training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews.insert(2, 'reaction', 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_reviews.insert(2, 'reaction', 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a combined dataframe of the positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reviews = pd.concat([pos_reviews, neg_reviews], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1063154 entries, 0 to 1063153\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   overall     1063154 non-null  int64 \n",
      " 1   reviewText  1062768 non-null  object\n",
      " 2   reaction    1063154 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 24.3+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_reviews['reviewText'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some reviews that do not contain text. We can remove those since they will not provide any information we can use for the classifying task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = combined_reviews[combined_reviews['reviewText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1062768 entries, 0 to 1063153\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   overall     1062768 non-null  int64 \n",
      " 1   reviewText  1062768 non-null  object\n",
      " 2   reaction    1062768 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 32.4+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optional:* Save the reviews dataframe to a CSV at this point, for further analysis outside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.to_csv('data/combined_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main combined dataframe has over 1 million records. We will reduce the amount for the classifier to 20,000 for an even split between the positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = reviews.groupby('reaction').apply(lambda x: x.sample(n=10000)).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    10000\n",
       "positive    10000\n",
       "Name: reaction, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['reaction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   overall     20000 non-null  int64 \n",
      " 1   reviewText  20000 non-null  object\n",
      " 2   reaction    20000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data, we will create a list of positive reviews and another of the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sample_df.loc[sample_df['reaction'] == 'positive']\n",
    "pos_list = pos_df['reviewText'].tolist()\n",
    "\n",
    "neg_df = sample_df.loc[sample_df['reaction'] == 'negative']\n",
    "neg_list = neg_df['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the first 10 records of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handy snack',\n",
       " \"So happy to have finally found a shelf stable until opened replacement for half and half!. Actually love the flavor better than half and half now too.  I've also tried the Vanilla Nut Pods...very nice and pleasing vanilla without being overbearing.  You do not need as much Nut Pods to cream as real half and half so if you judge if you've added enough don't worry it looks darker than the same amount of half and half.  I'm organic but I require good flavor plus healthy products.\",\n",
       " 'Always a great product and well we enjoy them',\n",
       " \"These are fabulous.  Not a diet food, just  a healthy delicious snack. It's  scrumptious.\",\n",
       " 'Exactly as described!',\n",
       " 'Love this yogurt! Become my favorite!',\n",
       " 'good product for a fair price and conveniently delivered.',\n",
       " \"I can bake a lot of things with this product and the taste it's really good!! I like the texture and flavor combined with sucralose and my hubby love it too, considering that he is really picky to eat sweet things.\\nI'll buy it again for sure!\",\n",
       " 'Taste great',\n",
       " 'this is great stuff. I made Canadian bacon 25lbs. corned beef 15lbs. pastrami 15lbs. buckboard bacon 20 lbs. and did an experiment with cured breakfast sausage with this so far and still have 3/4 of the bag left!  great stuff!!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not a fan of this kind of taste.',\n",
       " \"This is good cocoa, but you'd almost have better luck just opening the K-cup and stirring it in. I have found that if I make it as per the box directions, I'll have about 1/4 of the cocoa still inside the cup.\\n\\nAlso, you do not want to do this on the large cup size - it will be so diluted that will not want to drink it. I make it using the middle sized cup and use 2 k-cups.\\n\\nI got this on sale for $7, so it wasn't too bad of a price, but I think in the future I will just stick to buying a container of hot cocoa.\",\n",
       " 'I bought three different colors of candy melts and this one did not melt. It remained clumpy and thick. Needless to say it was a waste for our Easter treats!',\n",
       " \"in my struggle to bake with less carbs, these mixes upset my stomach and I've not returned to them after my first disasterous attempts.  The sugar free cakes look like regular cakes when baked, and they taste good and go down well, but I found they cause me gastric distress.  What I do now is buy regular cake mix, and add fiber to it, in the form of almond flour and corn bran (also oat bran is high fiber, I buy my bran products from Honeyville).  I add the required oil and eggs and use about 1/2 or sometimes a third of the box mix (because I usually make one layer at a time), and add the fiber I want approximately 1/4 c almond meal and about 1/4 c corn bran, and the cake raises just as if I'd made no alterations to the dry ingredients, and it tastes fine.  If I'm using a chocolate cake mix, I also add extra cocoa powder as I like a very chocolatey cake.  Buy cake mixes when they're on sale and experiment.  To make the cake sweeter, after I've added the almond flour, corn bran and chocolate, I add abit of no calorie, no carb Stevia.  As the mix uses sugar, you won't be able to taste the Stevia (or whichever sugar substitute you like).  If you're a low carber, pre-diabetic or diabetic, you should still be able to enjoy a small piece of cake now and again (check with your health provider).  This works much better for me than the sugar free cake mixes, and causes me no stomach distress.  I never even got to the sugar free icings after what the sugar free cake mixes put me through.\\n\\nUpdate 10/19/13 - Using a regular cake mix, I've come up with a reduced carb recipe I can eat without gastric distress.\\n\\n1/3 of vanilla cake mix (save rest of mix for another recipe)\\n75 grams carbquik (a low carb flour substitute sold here or on netrition dot com)\\n50 grams almond flour (I like Honeyville but Trader Joes works just as well)\\n7 grams of Stevia (Costco dot com)\\n1/2 teaspoon baking powder\\n1 teaspoon vanilla extract (more if you prefer)\\n1/2 teaspoon almond extract\\npinch of salt\\n\\nadd eggs, fat and liquids as per back of cake mix package.  the substitutes give a single layer cake that rises and tastes like a traditional cake, but with significantly fewer carbs, as carbquik has just 6 net carbs per cup (as opposed to 80 carbs in many flours), and almond flour has significantly fewer carbs as well, and stevia has no carbs. The sugar in the cake mix covers the aftertaste that I can usually detect with stevia. Also the flour substitute carbquik has a faint aftertaste, which the flour and sugar in the cake mix, plus the good tasting almond flour, covers up.  Making the substitutions, I get a cake that tastes and has a very similar texture to a traditionally made cake, with a much lower carb hit and no stomach distress.\\nEnjoy!\",\n",
       " \"I order Twizzlers cherry bites (rather than buying locally) because my family eats a LOT of them, and because we have found them to be much fresher than the local fare. But in this shipment, even though each bag was well-sealed, the cherry bites were very stale. Although the Twizzlers from local stores tend to be stale, this shipment was more stale than any I've ever purchased at the grocery store. My family will not eat them because their they are harder and waxier than they should be.\",\n",
       " \"I'm living proof people will buy anything, regardless of lack of flavor.\",\n",
       " \"I have a love/hate relationship with Twinings teas. Unfortunately, the two I love best have been discontinued (Vanilla Black Tea and Indian Spiced Chai Tea). Since this tea claims to combine vanilla and chai, I decided to try it.\\n\\nIt is remarkably bland and frankly, the chai spices are barely perceptible, whereas the vanilla taste is non-existent. It is not a particularly potent tea either. I also agree that there is an odd, slightly fishy taste to this tea. I will finish the box (I started putting cinnamon sticks in it to give it some flavor), but this was a real miscalculation on Twinings' part. I wrote them about it and they didn't even bother to reply. My guess is I am not the only one disappointed by this tea, and since it isn't exactly cheap, my advice would be to look elsewhere if you want chai tea.\",\n",
       " \"As I said in another review of organic earl grey, different brand, it just does't cut it, still preferring Ahmad.\\nOrganic was recommended to me, but I am not seeing it.\",\n",
       " \"Really cute can that won't fit into a yeti container.  Cherry tastes a bit like cough syrup but this flavor is slightly more drinkable than the watermelon/kiwi flavor.  Still not as good as plain soda water.  Really disappointed.\",\n",
       " \"I had my doubts about buying soy milk - or any other food product - on line and was correct in my reservations. This stuff, while seemingly the same brand that I buy at the store, apparently sits in a warehouse or is just made different because it not only tastes different but it does not foam up for latte's. Bak to Costco!\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things cleaner for the classifier, we will lowercase all the words in the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list_lowered = [word.lower() for word in pos_list]\n",
    "neg_list_lowered = [word.lower() for word in neg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handy snack']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list_lowered[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not a fan of this kind of taste.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_list_lowered[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use what is called the 'bag of words' strategy to divide up indicator words for our classifier. This means we will take all words from all respective reviews, and then use those to train the classifier. The reviews are in a list format, so we will have to turn these into string types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list comprehension \n",
    "pos_list_to_string = ' '.join([str(elem) for elem in pos_list_lowered]) \n",
    "neg_list_to_string = ' '.join([str(elem) for elem in neg_list_lowered])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll remove stop words and punctuation. From NLTK, we'll specify stop words to look for are in English, and then call upon punctuation for the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english') + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tokenize the data, we will use nltk's Whitespace Tokenizer, because this will let us preserve any contractions that may have been used in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pos_list = [w for w in tokenizer.tokenize(pos_list_to_string) if w not in stop]\n",
    "filtered_neg_list = [w for w in tokenizer.tokenize(neg_list_to_string) if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handy',\n",
       " 'snack',\n",
       " 'happy',\n",
       " 'finally',\n",
       " 'found',\n",
       " 'shelf',\n",
       " 'stable',\n",
       " 'opened',\n",
       " 'replacement',\n",
       " 'half',\n",
       " 'half!.',\n",
       " 'actually',\n",
       " 'love',\n",
       " 'flavor',\n",
       " 'better',\n",
       " 'half',\n",
       " 'half',\n",
       " 'too.',\n",
       " \"i've\",\n",
       " 'also',\n",
       " 'tried',\n",
       " 'vanilla',\n",
       " 'nut',\n",
       " 'pods...very',\n",
       " 'nice',\n",
       " 'pleasing',\n",
       " 'vanilla',\n",
       " 'without',\n",
       " 'overbearing.',\n",
       " 'need']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pos_list[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove periods that may have been connected to words, using regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pos_list2 = [w.strip(string.punctuation) for w in filtered_pos_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['handy',\n",
       " 'snack',\n",
       " 'happy',\n",
       " 'finally',\n",
       " 'found',\n",
       " 'shelf',\n",
       " 'stable',\n",
       " 'opened',\n",
       " 'replacement',\n",
       " 'half',\n",
       " 'half',\n",
       " 'actually',\n",
       " 'love',\n",
       " 'flavor',\n",
       " 'better',\n",
       " 'half',\n",
       " 'half',\n",
       " 'too',\n",
       " \"i've\",\n",
       " 'also',\n",
       " 'tried',\n",
       " 'vanilla',\n",
       " 'nut',\n",
       " 'pods...very',\n",
       " 'nice',\n",
       " 'pleasing',\n",
       " 'vanilla',\n",
       " 'without',\n",
       " 'overbearing',\n",
       " 'need']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pos_list2[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_neg_list2 = [w.strip(string.punctuation) for w in filtered_neg_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use nltk's Frequency Distribution to get a preview of the most common words in each list. As we can see from this, there is some overlap. Further options for reducing overlap include looking at indicator words based on a specific type of speech, such as adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_pos = nltk.FreqDist(filtered_pos_list2)\n",
    "fd_neg = nltk.FreqDist(filtered_neg_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 2960),\n",
       " ('great', 2787),\n",
       " ('like', 2191),\n",
       " ('love', 1931),\n",
       " ('taste', 1742),\n",
       " ('flavor', 1675),\n",
       " ('tea', 1464),\n",
       " ('coffee', 1411),\n",
       " ('one', 1286),\n",
       " ('use', 1229),\n",
       " ('product', 1216),\n",
       " ('it', 1113),\n",
       " ('price', 953),\n",
       " ('really', 952),\n",
       " ('best', 879)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_pos.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 4318),\n",
       " ('taste', 3671),\n",
       " ('flavor', 2324),\n",
       " ('product', 2080),\n",
       " ('good', 2011),\n",
       " ('one', 1866),\n",
       " ('it', 1729),\n",
       " ('would', 1694),\n",
       " ('coffee', 1513),\n",
       " ('tea', 1401),\n",
       " ('much', 1278),\n",
       " ('buy', 1183),\n",
       " ('really', 1162),\n",
       " ('get', 1127),\n",
       " ('even', 1113)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_neg.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the sets of words, we'll need to convert them to feature sets as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_features(words):\n",
    "    return dict([(word, True) for word in words.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label the two sets of word features and combine them in one set for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_features = [(word_features(f), 'pos') for f in filtered_pos_list2]\n",
    "\n",
    "negative_features = [(word_features(f), 'neg') for f in filtered_neg_list2]\n",
    "\n",
    "labeledwords = positive_features + negative_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'stirring': True}, 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(negative_features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(negative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196362"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272944"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly shuffle the labeled words, and then create a train and test set to reflect a split of the word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labeledwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = labeledwords[2000:], labeledwords[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide examples to test the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(word_features('I hate this product, it tasted weird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classify(word_features('I love this product, it tasted great')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy of the classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see what the most informative features are for the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              disgusting = True              neg : pos    =     47.9 : 1.0\n",
      "                   awful = True              neg : pos    =     40.2 : 1.0\n",
      "                returned = True              neg : pos    =     30.5 : 1.0\n",
      "           disappointing = True              neg : pos    =     29.8 : 1.0\n",
      "                   threw = True              neg : pos    =     28.6 : 1.0\n",
      "                horrible = True              neg : pos    =     27.9 : 1.0\n",
      "                dextrose = True              neg : pos    =     26.6 : 1.0\n",
      "                     yum = True              pos : neg    =     26.4 : 1.0\n",
      "            maltodextrin = True              neg : pos    =     23.5 : 1.0\n",
      "               tasteless = True              neg : pos    =     21.5 : 1.0\n",
      "                   trash = True              neg : pos    =     21.3 : 1.0\n",
      "               returning = True              neg : pos    =     19.9 : 1.0\n",
      "                     ugh = True              neg : pos    =     19.4 : 1.0\n",
      "                  edible = True              neg : pos    =     17.4 : 1.0\n",
      "                modified = True              neg : pos    =     16.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
